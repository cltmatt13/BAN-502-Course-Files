---
title: "Module4_Assignment2"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

```{r, include = FALSE}
library("gridExtra")
library("vip")
library("ranger")
library("tidyverse")
library("tidymodels")
library("caret")
library(mice) #package for imputation
library(VIM) #visualizing missingness
library(naniar) #visualizing missingness
library(skimr) #alternative way to view dataset summaries
library(UpSetR)
library(gridExtra)
```

```{r,}
drug <- read_csv("drug_data-1.csv")
```

```{r}
names(drug) = c("ID", "Age", "Gender", "Education", "Country", "Ethnicity","Nscore", "Escore", "Oscore", "Ascore", "Cscore", "Impulsive","SS", "Alcohol", "Amphet", "Amyl", "Benzos", "Caff", "Cannabis","Choc", "Coke", "Crack", "Ecstasy", "Heroin", "Ketamine", "Legalh","LSD", "Meth", "Mushrooms", "Nicotine", "Semer", "VSA")

#str(drug)
```

```{r}
drug[drug == "CL0"] = "No"
drug[drug == "CL1"] = "No"
drug[drug == "CL2"] = "Yes"
drug[drug == "CL3"] = "Yes"
drug[drug == "CL4"] = "Yes"
drug[drug == "CL5"] = "Yes"
drug[drug == "CL6"] = "Yes"
```

```{r}
drug_clean = drug %>% 
  mutate_at(vars(Age:Ethnicity), funs(as_factor)) %>%
  mutate(Age = factor(Age, labels = c("18_24", "25_34", "35_44","45_54", "55_64", "65_"))) %>%
  mutate(Gender = factor(Gender, labels = c("Male", "Female"))) %>%
  mutate(Education = factor(Education, labels =c("Under16", "At16", "At17", "At18", "SomeCollege","ProfessionalCert", "Bachelors", "Masters", "Doctorate"))) %>%mutate(Country = factor(Country,labels = c("USA", "NewZealand", "Other", "Australia","Ireland","Canada","UK"))) %>%
  mutate(Ethnicity = factor(Ethnicity,labels = c("Black", "Asian", "White", "White/Black", "Other","White/Asian", "Black/Asian"))) %>%
  mutate_at(vars(Alcohol:VSA), funs(as_factor)) %>%select(-ID)
```
```{r}
#str(drug_clean)
```

```{r}
drug_clean = drug_clean %>% 
  select(!(Alcohol:Mushrooms)) %>% 
  select(!(Semer:VSA))
names(drug_clean)
```

## Task 1

```{r}
#str(drug_clean)
#summary(drug_clean)
#skim(drug_clean)
```
```{r}
gg_miss_var(drug_clean)
```
```{r}
gg_miss_case(drug_clean)
```

After using several methods to check for missingness in the drug_clean data set, there does not appear to be any missing data.

## Task 2

```{r}
set.seed(1234)
drug_clean_split = initial_split(drug_clean, prob = 0.70, strata = Nicotine)
train = training(drug_clean_split)
test = testing(drug_clean_split)
```

## Task 3

```{r}
p1 = ggplot(train, aes(x = Age, fill = Nicotine)) + geom_bar(position = "fill") + theme(axis.text.x = element_text(size=6, angle = 45, vjust = 1, hjust=1))
p2 = ggplot(train, aes(x = Gender, fill = Nicotine)) + geom_bar(position = "fill")
p3 = ggplot(train, aes(x = Education, fill = Nicotine)) + geom_bar(position = "fill") + theme(axis.text.x = element_text(size=6, angle = 45, vjust = 1, hjust=1))

grid.arrange(p1,p2,p3, ncol = 2)
```


```{r}
p4 = ggplot(train, aes(x = Country, fill = Nicotine)) + geom_bar(position = "fill") + theme(axis.text.x = element_text(size=6,angle = 45, vjust = 1, hjust=1))
p5 = ggplot(train, aes(x = Ethnicity, fill = Nicotine)) + geom_bar(position = "fill") + theme(axis.text.x = element_text(size=6,angle = 45, vjust = 1, hjust=1))

grid.arrange(p4,p5, ncol = 2)
```


```{r}
p6=ggplot(train, aes(x = Nscore, y = Nicotine)) + geom_boxplot()
p7=ggplot(train, aes(x = Escore, y = Nicotine)) + geom_boxplot()
p8=ggplot(train, aes(x = Oscore, y = Nicotine)) + geom_boxplot()
p9=ggplot(train, aes(x = Ascore, y = Nicotine)) + geom_boxplot()

grid.arrange(p6,p7,p8,p9, ncol = 2)
```

```{r}
p10=ggplot(train, aes(x = Cscore, y = Nicotine)) + geom_boxplot()
p11=ggplot(train, aes(x = Impulsive, y = Nicotine)) + geom_boxplot()
p12=ggplot(train, aes(x = SS, y = Nicotine)) + geom_boxplot()

grid.arrange(p9,p10,p11, ncol = 2)
```
## Task 4
```{r}
set.seed(123)
rf_folds = vfold_cv(train, v = 5)
```


```{r}
drug_clean_recipe = recipe(Nicotine ~., train) %>%
  step_dummy(all_nominal(), -all_outcomes())

rf_model = rand_forest(mtry = tune(), min_n = tune(), trees = 100) %>% 
  set_engine("ranger", importance = "permutation") %>% 
  set_mode("classification")

drug_clean_wflow = 
  workflow() %>% 
  add_model(rf_model) %>% 
  add_recipe(drug_clean_recipe)

rf_grid = grid_regular(
  mtry(range = c(2, 8)), 
  min_n(range = c(5, 20)), 
  levels = 10)

set.seed(123)
rf_res_tuned = tune_grid(
  drug_clean_wflow,
  resamples = rf_folds,
  grid = 20)

```

```{r}
rf_res_tuned %>%
  collect_metrics() %>%
  filter(.metric == "accuracy") %>%
  select(mean, min_n, mtry) %>%
  pivot_longer(min_n:mtry,
    values_to = "value",
    names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "Accuracy")
```

```{r}
rf_res_tuned %>%
  collect_metrics() %>%
  filter(.metric == "accuracy") %>%
  mutate(min_n = factor(min_n)) %>%
  ggplot(aes(mtry, mean, color = min_n)) +
  geom_line(alpha = 0.5, size = 1.5) +
  geom_point() +
  labs(y = "Accuracy")
```

## Task 5

```{r}
best_rf = select_best(rf_res_tuned, "accuracy")

final_rf = finalize_workflow(drug_clean_wflow,
  best_rf)

final_rf
```
```{r}
final_rf_fit = fit(final_rf, train)

final_rf_fit %>% pull_workflow_fit() %>% vip(geom = "point")
```

The two greatest variables that predict nicotine usage are SS (a measure of sensation seeking) and Oscore ( a measure of openess to experiences).

## Task 6

```{r}
trainpredrf = predict(final_rf_fit, train)
head(trainpredrf)
```
```{r}
confusionMatrix(trainpredrf$.pred_class, train$Nicotine, 
                positive = "Yes")
```

```{r}
testpredrf = predict(final_rf_fit, test)
head(testpredrf)
```
```{r}
confusionMatrix(testpredrf$.pred_class, test$Nicotine, 
                positive = "Yes")
```

## Task 7

The model would have real world applications when studying the best way to deter nicotine usage based on the metrics for the various variables such as "sensation seeking" or "openness to new experiences."  In its current state though the accuracy rate between the training set at .8564 and testing set at .7346 is probably too great for use in the rea world.  The model should be modified to include a greater number of trees in our random forest to determine a better fit.  
